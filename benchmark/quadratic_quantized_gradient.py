from typing import List, Optional

import torch
import torch.nn as nn
import typer

from benchmark.utils import param_norm_win_condition, trial
from heavyball.utils import set_torch

app = typer.Typer(pretty_exceptions_enable=False)
set_torch()

configs = {
    "trivial": {"bins": 2**6},
    "easy": {"size": 2**5},
    "medium": {"size": 2**4},
    "hard": {"size": 2**3},
    "extreme": {"size": 2**2},
    "nightmare": {"size": 2**1},
}


class Model(nn.Module):
    def __init__(self, bins: int, size=128):
        super().__init__()
        self.param = nn.Parameter(torch.randn(size))
        self.bins = bins / 2  # because +/-

    def forward(self):
        grad = self.param  # assuming MSE(param, 0)
        absmax = grad.abs().max()
        grad = grad / absmax * self.bins
        grad = grad.round() / self.bins * absmax
        grad = grad.detach()

        loss = self.param.square()
        param_with_grad = self.param * grad
        return (loss.detach() + param_with_grad - param_with_grad.detach()).mean()


@app.command()
def main(
    method: List[str] = typer.Option(["qr"], help="Eigenvector method to use (for SOAP)"),
    dtype: List[str] = typer.Option(["float32"], help="Data type to use"),
    size: int = 1024,
    batch: int = 256,
    steps: int = 100,
    weight_decay: float = 0,
    opt: List[str] = typer.Option(["ForeachSOAP"], help="Optimizers to use"),
    trials: int = 10,
    win_condition_multiplier: float = 1.0,
    config: Optional[str] = None,
):
    kwargs = configs[config or "trivial"]
    model = Model(**kwargs).cuda()

    def data():
        return None, None

    trial(
        model,
        data,
        None,
        param_norm_win_condition(win_condition_multiplier * 1e-7, 0),
        steps,
        opt[0],
        weight_decay=weight_decay,
        failure_threshold=2,
        trials=trials,
    )


if __name__ == "__main__":
    app()
